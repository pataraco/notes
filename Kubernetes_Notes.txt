Kubernetes (k8s) Notes
----------------------

My kubernetes notes.

Questions
----------
1) Are you ready to handle k8s release schedule?
  - major releases: 4 x year
  - minor releases: 12+ x year
  - support: N-2 ~ 9 months
2) How many clusters will you need?
  - need to be ready to expand/deploy to (N)
  - 1 cluster / team|project
3) How mature is your SDN (SW Defined Network)?
  - L7/LB

TODO
----
- https://github.com/ahmetb/kubectx
- https://kubernetes.io/docs/reference/kubectl/cheatsheet/
- https://kubernetes.io/docs/reference/kubectl/jsonpath/
- source <(kubectl completion bash)

Components
----------

Master Components
-----------------
control plane. global decisions. events.

 - kube-apiserver: exposes API, scales
 - etcd: key/val store of cluster data, always backup
 - kube-scheduler: schedules newly created pods to run on specific nodes
 - controller: control loop that watches the shared state of the cluster
     through the apiserver and makes changes attempting to move the current
     state towards the desired state.
 - kube-controller-manager: runs controllers
   - node controller: notices/responds to nodes going down
   - replication controller: maintains correct number of pods for replication
     controller objects
   - endpoints controller: populates the Endpoints object (joins Services & Pods)
   - service account & token controllers: create default accounts and API access
     tokens for new namespaces
 - cloud-controller-manager: runs controllers that interact with the underlying
     cloud providers
   - node controller: checks cloud provider it a node has been deleted in the
     cloud after it sops responding
   - route controller: set up routes in the underlying cloud infra
   - service controller: create, update, deleted cloud provider load balancers
   - volume controller: create, attach, mount volumes and interacting with the
     cloud provider to orchestrate volumes

Node Components
---------------
run on every node, maintain running pods, provide k8s runtime environment

 - kubelet: agent, makes sure that containers are running in a pod with PodSpecs
 - kube-proxy: enables the k8s service abstraction my maintaining network rules
   on the host and performing connection forwarding
 - container runtime: software responsible for running containers (docker,
   containerd, cri-o, rktlet, and any k8s CRI (container Runtime interface))

Addons
------
pods and services that implement cluster features. managed by deployments, 
replication controllers, etc.

 - extended list:
   https://kubernetes.io/docs/concepts/cluster-administration/addons/

 - DNS: all k8s clusters should have cluster DNS. DNS server, serves DNS records
   for k8s services. containers started by k8s automatically include this DNS
   server in the DNS searches
   <service-name>.<namespace-name>.svc.cluster.local
 - Web UI (dashboard): general purpose, web-based UI for k8s clusters. allows
   management, troubleshooting of cluster applications and the cluster
   (https://github.com/kubernetes/dashboard)

   1. To deploy Dashboard, execute following command:
      $ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml
   2. To access Dashboard from locahost create a secure channel to the Kubernetes cluster. Run the following command:
      $ kubectl proxy
   3. Now access Dashboard at:
      http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/.

 - Container resource monitoring: records generic time-series container metrics 
   in a central db and a UI to browse the data
 - Cluster-level Logging: saves container logs to a central log store with
   search/browsing interface

Objects
-------
persistent entities in the k8s system which represent the state of the cluster
 - which containerized apps are running and on which nodes
 - resources available to those applications
 - applications policies: restart, upgrades, fault-tolerance
 - "record of intent": k8s contantly work to ensure that create objects exist
   k8s desired state
 - use k8s API to create, modify, delete objects
 - object spec: describes desired state - characteristics
 - object status: actual state
 - required fields:
   - apiVersion: version of the k8s API using to create the object
   - kind: kind of object to create
   - metadata: data to uniquely identify the object, including a `name`, `UID`
     and `namespace`
   - spec: precise object format
   - name: client provided
   - UID: k8s system generated
   - namespace: virtual cluster backed by the same physical cluster, unique 
     objects within
   - labels/selectors: identifying attributes, organize, select
   - annotations: arbitrary, non-identifying metadata. uri's, version, etc.
   - field selectors: select resources based on the value of one or more
     resource fields (metadata.name=my_service, metadata.namespace!=default)


   Spec formats:
   - https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.14/

Architecture
------------
 - Nodes: worker machine (minion). managed by the master components.
   - status:
     - addresses: HostName, ExternlIp, InternalIp
     - condition: OutOfDisk, Ready, MemoryPressure, PIDPressure, DiskPressure, NetworkUnavailable
     - capacity: resouces available on the node: CPU, memory, max number of pods
     - info: general info, kernel version, k8s version, Docker version, O.S. name
   - not inherently created by k8s. created externally by cloud provider
   - interacting components: node controller, kubelet, kubectl
   - registration: with kubelet flag --register-node (default)
 - Master-Node communication

Containers
----------
   - Images
   - Container Environment Variables
   - Runtime Class
   - container Lifecycle Hooks

Workloads
---------
 - Pods: managed by controllers
 - Controllers:
   - ReplicaSet: maintains a stable set of replica Pods running, owner of a set
     of Pods
   - ReplicationController: ensures specified number of pod replicas are running
   - Deployments: roll out ReplicaSets, declare pods states, rollback, scale,
     pause, statuses, cleanup
     (a Deployment that configures a ReplicaSet in now the recommended way to
      set up replication)
   - StatefulSets: stable, unique network identifiers, persistent storage,
     ordered, graceful deployments and scaling, automated rolling updates
   - DaemonSet: ensures that all (or some) Nodes run a copy of a Pod, run cluster
     storage daemon, run logs collection daemon on every node, run monitoring
     daemon on every node. one set per each type of daemon
   - Garbage Collection: deletes certain objects (dependents) that once had an
     owner, but no longer have an owner. metadata.ownerReferences
   - TTL Controller: limit the lifetime of resource objects that have finished
     execution (currently only handles jobs)
   - Jobs: creates one or more Pods and ensures that a specified number of them
     successfully terminate
   - CronJob: create Jobs on a time-based schedule

Services, Load Balancing, Networking
------------------------------------
https://kubernetes.io/docs/concepts/services-networking/service
https://kubernetes.io/docs/tutorials/services/source-ip/
https://kubernetes.io/docs/concepts/services-networking/connect-applications-service

 - Services: defines a logical set of Pods and access policy determined by 
   Label Selector
 - DNS for Services and Pods
 - Connnectiong Applications with Services
 - Ingress
 - Ingress controllers
 - Network Policies
 - Adding entries to Pod /etc/hosts with HostAliases
 - ClusterIP -> NodePort -> LoadBalancer, ExternalName

Building Blocks (Primary)
-------------------------
if you can explain what each one of these do and how they build on each other,
then you'll have a good grasp of k8s:

 - Container
 - Pod
 - ReplicaSet or Controller
 - Deployment
 - Service
 - Ingress Rule

Building Blocks (Secondary)
---------------------------
 - Namespaces
 - Configmap
 - Secrets
 - Limits
 - env and envFrom
 - Node and Pod Affinity and Antiaffinity
 - Resource limits
 - Daemon Set
 - Stateful Set
 - Persistent Volume
 - Persistent Volume Claim

Installation
------------
brew install kubernetes-cli
   (or install with [Docker Desktop](www.docker.com/products/docker-desktop))
kubectl version [--short]  # get client and server versions
brew cask install virtualbox
brew cask install minikube
minikube version
minikube start
minikube start \
    --network-plugin=cni \
    --enable-default-cni \
    --container-runtime=containerd \
    --container-runtime=cri-o \
    --container-runtime=rkt \
    --bootstrapper=kubeadm
kubectl run hello-minikube --image=gcr.io/google_containers/echoserver:1.4 --port=8080
kubectl run hello-minikube --image=k8s.gcr.io/echoserver:1.10 --port=8080
kubectl run --generator=run-pod/v1
s
kubectl expose deployment hello-minikube --type=NodePort
kubectl get pods
minikube service hello-minikube --url
kubectl delete deployment hello-minikube
minikube addons list
minikube addons enable ADDON
minikube stop


Configuration
-------------
EKS
---
1. create EKS cluster (creates master nodes)
2. create worker nodes
3. enable worker nodes to join the cluster (via ConfigMap)
   e.g. docs.aws.amazon.com/eks/latest/userguide/getting-started-console.html
   --- aws-auth-cm.yaml (begin) ---
   apiVersion: v1
   kind: ConfigMap
   metadata:
     name: aws-auth
     namespace: kube-system
   data:
     mapRoles: |
       - rolearn: <ARN of instance role>
         username: system:node:{{EC2PrivateDNSName}}
         groups:
           - system:bootstrappers
           - system:nodes
   --- aws-auth-cm.yaml (end) ---
   kubectl apply -f aws-auth-cm.yaml

Commands
--------
Kubectl book: https://kubectl.docs.kubernetes.io/

Reference:
  https://kubernetes.io/docs/reference/

 - Imperative vs. Declaritive

kubectl get      - list one or many resources.
kubectl describe - show detailed information about a specific or many resources.
kubectl logs     - print the logs from a container in a pod or specified resource.
kubectl exec     - execute a command on a container in a pod
kubectl apply    - execute a command on a container in a pod

 - minikube ip
 # API of the pod
 - curl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/

 - kubectl $CMD [--help] [-o wide|json|yaml] [-l $KEY=$VAL]
 - kubectl api-resources [--namespaced=true|false]  #  list supported API resources
 - kubectl cluster-info
 - kubectl config current-context
 - kubectl config get-clusters
 - kubectl config get-contexts
 - kubectl config set-context $(kubectl config current-context) --namespace=$NAMESPACE
 - kubectl config use-context $CONTEXT
 - kubectl config use-context minikube
 - kubectl config view
 - kubectl create secret generic $SECRET_NAME --from-literal=$KEY=$VAL [-n $NAMESPACE]
 - kubectl delete secret $SECRET_NAME [-n $NAMESPACE]
 - kubectl delete service $SERVICE
 - kubectl delete service -l $KEY=$VAL
 - kubectl describe daemonset aws-node -n kube-system [| grep Image]
 - kubectl describe deployment coredns -n kube-system [| grep Image]
 - kubectl describe configmap aws-auth -n kube-system
 - kubectl describe namespace [$NAMESPACE_NAME]
 - kubectl describe pods [$POD_NAME]
 - kubectl describe secrets [$SECRET]
 - kubectl describe services [$SERVICE] [-n $NAMESPACE]
 - kubectl describe services/$SERVICE
 - kubectl exec -ti $POD_NAME curl localhost:8080
 - kubectl exec [-ti] $POD_NAME $CMD
 - kubectl expose deployment/$DEPOLYMENT --type NodePort --port 8080
 - kubectl expose deployment/$DEPOLYMENT --type=NodePort --port=8080
 - kubectl expose deployment $DEPOLYMENT --port=8080 --target-port=80 --name nginx
 - kubectl get configmap
 - kubectl get deployments
 - kubectl get namespace
 - kubectl get nodes
 - kubectl get pods -n kube-system -l k8s-app=kube-dns
 - kubectl get pods --context=minikube
 - kubectl get pods --field-selector status.phase=Running
 - kubectl get pods --field-selector status.phase=Running,spec.restartPolicy=Always
 - kubectl get pods -l 'env in (prod),tier in (web)'
 - kubectl get pods -l 'env in (prod, qa),tier in (web)'
 - kubectl get pods -l 'env,env notin (qa)'
 - kubectl get pods -l env==prod,tier==web
 - kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{"\n"}}{{end}}
 - kubectl get pods [-n $NAMESPACE | --namespace=$NAMESPACE]
 - kubectl get secrets
 - kubectl get services
 - kubectl get services/$SERVICE -o go-template='{{(index .spec.ports 0).nodePort}}'
 - kubectl get statefulsets,services --field-selector metadata.namespace!=default
 - kubectl port-forward TYPE/NAME [options] [LOCAL_PORT:]REMOTE_PORT [...[LOCAL_PORT_N:]REMOTE_PORT_N]
 - kubectl label <OBJECT> $OBJECT_NAME $KEY=$VAL
 - kubectl log $POD_NAME
 - kubectl proxy
 - kubectl scale deployments $DEPLOYMENT --replicas=$X

API
---
API Conventions:
  https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md
API Overview:
  https://kubernetes.io/docs/reference/using-api/api-overview/
Access:
  https://kubernetes.io/docs/reference/access-authn-authz/controlling-access/
Python Client:
  https://github.com/kubernetes-client/python

"selector": {
    "component" : "redis"
}

Labels & Selectors
------------------

Recommended Labels
------------------
https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/

a common set of labels allows tools to work interoperably, describing object in
a common manner that all tools can underststand. and describe applications in a
way that can be queried

 - organized around the cnocept of an application
 - applications described with metadata
 - shared labels and annotations share a common prefix: `app.kubernetes.io`
 - labels without a prefix are private to users
 - a shared prefix ensures that shared labels do not interfere with custom user 
   labels

selector:
    component: redis

selector:
  matchLabels:
    componect: redis
  matchExpressions:
    - {key: env, operator: In, values: [prod, qa]}
    - {key: tier, operator: NotIn, values: [web]}

(operators: In, NotIn, Exists, DoesNotExist)

Issues
------

Upgrading
------
EKS
---
1. upgrade EKS cluster version
  a. Terraform v0.11 and eks module (terraform-aws-modules/terraform-aws-eks)
   - you can update/specify to the next higher version and terraform will update EKS and the ASG/LC.
  b. Or via AWS CLI
   - aws eks --region REGION update-cluster-version --name CLUSTER_NAME --kubernetes-version VERSION
   - aws eks --region region describe-update --name prod --update-id UPDATE_ID
2. move pods
  a. with AWS AutoScaling (included with terraform-aws-modules/terraform-aws-eks)
   - Increase the ASG desired count and move the containers to the new host(s), drain the old host(s), stop ASG processes, terminate instances, reduce ASG desired count, enable ASG processes
3. check/patch the kube-proxy daemonset to match k8s version (1.12=>1.12.6, 1.13=>1.13.7, 1.14=> 1.14.6)
   - kubectl describe ds kube-proxy -n kube-system | grep Image
   - kubectl set image daemonset.apps/kube-proxy -n kube-system kube-proxy=602401143452.dkr.ecr.us-west-2.amazonaws.com/eks/kube-proxy:v1.12.6
4. check if your cluster is running CoreDNS
   - kubectl get pod -n kube-system -l k8s-app=kube-dns
5. check/set version of coredns deployment (1.12=>1.2.2, 1.13=>1.2.6, 1.14=> 1.3.1)
   - kubectl describe deployment coredns -n kube-system | grep Image
   - kubectl set image deployment.apps/coredns -n kube-system coredns=602401143452.dkr.ecr.us-west-2.amazonaws.com/eks/coredns:v1.2.2
6. check/set version of cluster's Amazon VPC CNI Plugin for Kubernetes (> 1.5.3)
   - kubectl describe daemonset aws-node --namespace kube-system | grep Image
   - kubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/release-1.5/config/v1.5/aws-k8s-cni.yaml
